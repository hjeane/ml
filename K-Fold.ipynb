{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac7dbcf",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.KFold\n",
    "\n",
    "* class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
    "n_splitsint, default=5\n",
    "Number of folds. Must be at least 2\n",
    "\n",
    "shufflebool, default=False 랜덤으로 섞음\n",
    "Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.\n",
    "\n",
    "random_stateint, RandomState instance or None, default=None\n",
    "When shuffle is True, random_state affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. See Glossary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990e0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f32fb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7fc09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d53bca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _BaseKFold.split at 0x0000028D6DC9FE20>\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "print(kfold.split(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18ba17bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기 150\n"
     ]
    }
   ],
   "source": [
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a42961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "       47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,\n",
      "       77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119]), array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
      "       146, 147, 148, 149]))\n"
     ]
    }
   ],
   "source": [
    "for i in kfold.split(features):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a51dabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[[ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
    "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
    "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
    "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
    "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
    "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
    "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
    "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
    "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
    "       147, 148, 149]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb7fc566",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "features_names",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AANACONDA\\Lib\\site-packages\\sklearn\\utils\\_bunch.py:54\u001b[0m, in \u001b[0;36mBunch.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AANACONDA\\Lib\\site-packages\\sklearn\\utils\\_bunch.py:39\u001b[0m, in \u001b[0;36mBunch.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deprecated_key_to_warnings[key],\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m     38\u001b[0m     )\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'features_names'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m iris \u001b[38;5;241m=\u001b[39m load_iris()\n\u001b[1;32m----> 3\u001b[0m iris_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39miris\u001b[38;5;241m.\u001b[39mdata, columns\u001b[38;5;241m=\u001b[39miris\u001b[38;5;241m.\u001b[39mfeatures_names)\n\u001b[0;32m      4\u001b[0m iris_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m iris\u001b[38;5;241m.\u001b[39mtarget\n\u001b[0;32m      5\u001b[0m iris_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32m~\\AANACONDA\\Lib\\site-packages\\sklearn\\utils\\_bunch.py:56\u001b[0m, in \u001b[0;36mBunch.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(key)\n",
      "\u001b[1;31mAttributeError\u001b[0m: features_names"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.features_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5768f5c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m kfold \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m kfold\u001b[38;5;241m.\u001b[39msplit(iris_df):\n\u001b[0;32m      4\u001b[0m     n_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      5\u001b[0m     label_train \u001b[38;5;241m=\u001b[39m iris_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[train_index]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iris_df' is not defined"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(f'##교차검증: {n_iter}')\n",
    "    print(f'학습 레이블 분포: {label_train.value_counts()}')\n",
    "    print(f'검증 레이블 분포: {label_test.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45b0ea59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차검증 정확도 : 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "1 검증세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "## 평균 검증 정확도: 1.0\n",
      "\n",
      "#2 교차검증 정확도 : 0.6667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "2 검증세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "## 평균 검증 정확도: 0.83335\n",
      "\n",
      "#3 교차검증 정확도 : 0.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "3 검증세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "## 평균 검증 정확도: 0.5555666666666667\n",
      "\n",
      "#4 교차검증 정확도 : 0.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "4 검증세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "## 평균 검증 정확도: 0.416675\n",
      "\n",
      "#5 교차검증 정확도 : 0.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "5 검증세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.33334\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_tset = label[train_index], label[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차검증 정확도 : {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print(f'{n_iter} 검증세트 인덱스: {test_index}')\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc585eeb",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.StratifiedKFold\n",
    "* class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92feb829",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00622e3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m      5\u001b[0m     n_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m     label_train \u001b[38;5;241m=\u001b[39m iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[train_index]\n",
      "File \u001b[1;32m~\\AANACONDA\\Lib\\site-packages\\sklearn\\utils\\_bunch.py:39\u001b[0m, in \u001b[0;36mBunch.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_deprecated_key_to_warnings\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}):\n\u001b[0;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deprecated_key_to_warnings[key],\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m     38\u001b[0m     )\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    n_iter += 1\n",
    "    label_train = iris['label'].iloc[train_index]\n",
    "    label_test = iris['label'].iloc[test_index]\n",
    "    print(f'## 교차검증: {n_iter}')\n",
    "    print(f'학습 레이블 데이터 분포: {label_train.value_counts()}')\n",
    "    print(f'검증 레이블 데이터 분포: {label_test.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6333de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증 1 \n",
      "label\n",
      "2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: count, dtype: int64\n",
      "## 교차검증 2 \n",
      "label\n",
      "1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "## 교차검증 3 \n",
      "label\n",
      "0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(features, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, test_index in skf.split(features , label):\n",
    "    # print(test_index)\n",
    "    n_iter +=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(f'## 교차검증 {n_iter} ')\n",
    "    print(label_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd323086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 교차 검증 정확도: 1, 학습데이터 크기: 2, 검증 데이터 크기: 3\n",
      "평균 검증 정확도: 0.98\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "cv_accuracy = []\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "\n",
    "print(f'{0} 교차 검증 정확도: {1}, 학습데이터 크기: {2}, 검증 데이터 크기: {3}')\n",
    "cv_accuracy.append(accuracy)\n",
    "\n",
    "print(f'평균 검증 정확도: {np.mean(cv_accuracy)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc100bf",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.cross_val_score\n",
    "\n",
    "* sklearn.model_selection.cross_val_score(estimator=알고리즘명, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
    "\n",
    "* estimatorestimator object implementing ‘fit’\n",
    "The object to use to fit the data.\n",
    "\n",
    ">>> from sklearn import datasets, linear_model\n",
    ">>> from sklearn.model_selection import cross_val_score\n",
    ">>> diabetes = datasets.load_diabetes()\n",
    ">>> X = diabetes.data[:150]\n",
    ">>> y = diabetes.target[:150]\n",
    ">>> lasso = linear_model.Lasso()\n",
    ">>> print(cross_val_score(lasso, X, y, cv=3))\n",
    "[0.3315057  0.08022103 0.03531816]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7676c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
